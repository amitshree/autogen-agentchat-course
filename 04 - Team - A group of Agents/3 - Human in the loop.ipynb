{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Interact with the Team from Your Application\n",
    "\n",
    "There are two main ways to provide feedback to the team while using your application:\n",
    "\n",
    "1. **During a run** – Use a `UserProxyAgent` while `run()` or `run_stream()` is executing.  \n",
    "2. **After a run ends** – Provide feedback as input when calling `run()` or `run_stream()` again.\n",
    "\n",
    "## Providing Feedback During a Run\n",
    "\n",
    "The `UserProxyAgent` is a special built-in agent that allows users to give feedback to the team while it is running.\n",
    "\n",
    "### How to Use the `UserProxyAgent`\n",
    "- Create an instance of `UserProxyAgent`.  \n",
    "- Add it to the team before starting the run.  \n",
    "- The team will decide when to ask for user feedback through the `UserProxyAgent`.\n",
    "\n",
    "### When is `UserProxyAgent` Called?\n",
    "- **In a RoundRobinGroupChat team** – It is called in the order it was added to the team.  \n",
    "- **In a SelectorGroupChat team** – The selector prompt or function decides when the `UserProxyAgent` is called.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create the agents.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)  # Use input() to get user input from console.\n",
    "\n",
    "# Create the termination condition which will end the conversation when the user says \"APPROVE\".\n",
    "termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create the team.\n",
    "team = RoundRobinGroupChat([assistant, user_proxy], termination_condition=termination)\n",
    "\n",
    "# Run the conversation and stream to the console.\n",
    "stream = team.run_stream(task=\"Suggest three creative ideas for a new mobile app.\")\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "await Console(stream)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Providing Feedback for the Next Run  \n",
    "\n",
    "In many cases, an application or user interacts with a team of agents in a loop:  \n",
    "\n",
    "1. The team runs until it meets a termination condition.  \n",
    "2. The application or user gives feedback.  \n",
    "3. The team runs again using that feedback.  \n",
    "\n",
    "## Why is This Useful?  \n",
    "This method works well in long-running sessions where communication happens asynchronously.  \n",
    "\n",
    "- After the team finishes a run, the application **saves the team’s state**.  \n",
    "- The state can be stored safely in a database or persistent storage.  \n",
    "- When feedback is received, the team **resumes from where it left off** and continues running.  \n",
    "\n",
    "This approach ensures smooth interactions between the team and the user, even across multiple sessions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create the agents.\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "assistant = AssistantAgent(\"assistant\", model_client=model_client)\n",
    "\n",
    "# Create the team setting a maximum number of turns to 1.\n",
    "team = RoundRobinGroupChat([assistant], max_turns=1)\n",
    "\n",
    "task = \"Suggest three creative ideas for a new mobile app.\"\n",
    "while True:\n",
    "    # Run the conversation and stream to the console.\n",
    "    stream = team.run_stream(task=task)\n",
    "    # Use asyncio.run(...) when running in a script.\n",
    "    await Console(stream)\n",
    "    # Get the user response.\n",
    "    task = input(\"Enter your feedback (type 'exit' to leave): \")\n",
    "    if task.lower().strip() == \"exit\":\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### You can see that the team stopped immediately after one agent responded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
